{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "moreira_pablo_TP1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbUp-sqG7EnA"
      },
      "source": [
        "#Trabajo práctico n°1#\n",
        "\n",
        "###Moreira Pablo###\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITXHXC8M7mk_"
      },
      "source": [
        "# Cargo librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt7qyRby72JB"
      },
      "source": [
        "import numpy as np #manejo de arreglos\n",
        "\n",
        "import matplotlib.pyplot as plt #gráficos\n",
        "\n",
        "from sklearn.decomposition import PCA #Componentes principales\n",
        "from sklearn.preprocessing import StandardScaler #Escalado de datos\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB #clasificador bayesiano ingenuo\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis  #discriminante lineal\n",
        "from sklearn.linear_model import LogisticRegression #regresión logística\n",
        "\n",
        "# matriz de confusión\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# métricas para evaluar la clasificación predicha\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "from sklearn.metrics import f1_score, classification_report, plot_roc_curve\n",
        "# divide en conjuntos para entrenar y para testeat\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Tamaño de gráficos\n",
        "plt.rcParams[\"figure.figsize\"] = (10,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhJfT_RgC6EH"
      },
      "source": [
        "# Datos y exploración\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKJI3mfGeIkq"
      },
      "source": [
        "# cargamos datos desde el drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# carpeta del drive\n",
        "path = '/content/drive/MyDrive/UNAB Ciencia de Datos en uso/Inferencia estadística/TP1/'\n",
        "\n",
        "filename = 'Breast Cancer Prediction1.csv'\n",
        "\n",
        "cols_a_usar = (1,2,3,4,5,6,7,8,9,10) #saco la columna de codigo aleatorio que no sirve\n",
        "\n",
        "datos = np.genfromtxt(path+filename, delimiter=',',usecols = cols_a_usar, skip_header=1) \n",
        "\n",
        "\n",
        "#como hay datos nulos, eliminamos todas estas filas con \"nan\"\n",
        "datos = datos[~np.isnan(datos).any(axis=1)]\n",
        "\n",
        "t = np.genfromtxt(path+filename, delimiter=',', usecols = cols_a_usar, max_rows=1, dtype=str) #genero los titulos\n",
        "print (t)\n",
        "\n",
        "X = datos[:,0:-1]\n",
        "print(X.shape)\n",
        "print(X[0:5,:])\n",
        "\n",
        "y = datos[:,-1]\n",
        "print(y.shape)\n",
        "print(y[0:5])\n",
        "\n",
        "# Separo en train/test. \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=88888)\n",
        "\n",
        "# Standarizo datos de ENTRENAMIENTO\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train) #calcula promedio y desvío\n",
        "X_train = scaler.transform(X_train) #estandariza con promedio y desvío anteriores\n",
        "\n",
        "# Standarizo datos de TESTEO con los mismos promedio y desvío calculados para entrenamiento\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Standarizo datos en general con los mismos promedio y desvío calculados para entrenamiento\n",
        "X= scaler.transform(X)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YGDqtYbITHJ"
      },
      "source": [
        "# Escalo los datos\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "X=scaler.transform(X)\n",
        "\n",
        "#Aplico Componentes principales\n",
        "pca = PCA()\n",
        "pca.fit(X,y)\n",
        "x_new = pca.transform(X)\n",
        "pca.components_[:,0] #vemos la influencia de las variables originales con las combinaciones lineales en pca.components_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3wEpTtLbMkM"
      },
      "source": [
        "print([round(x,3) for x in pca.components_[:,0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w93mRHsyUAjb"
      },
      "source": [
        "pca.components_[:,1] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EizZnsf_bbB9"
      },
      "source": [
        "print([round(x,3) for x in pca.components_[:,1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEOZw1VSIU3V"
      },
      "source": [
        "#Varianza explicada por cada componente\n",
        "print(pca.explained_variance_ratio_)\n",
        "print([round(x,14) for x in pca.explained_variance_ratio_])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKAt4Xm_Imrs"
      },
      "source": [
        "# Grafico las primeras dos componentes principales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRZ9FlrMIpkV"
      },
      "source": [
        "def myplot(score,coeff,labels=None,target_names=None,titulo1='Vista PCA',titulo2='Vista proyeccion var originales'):\n",
        "     x1 = score[:,0]\n",
        "     x2 = score[:,1]\n",
        "     n = coeff.shape[0]\n",
        "\n",
        "     clases = target_names\n",
        "     scatter = plt.scatter(x1, x2, c=y, alpha=1) #, cmap=colours)\n",
        "     plt.legend(handles=scatter.legend_elements()[0], labels=clases, fontsize=19)\n",
        "     print(scatter.legend_elements())\n",
        "     plt.legend(handles=scatter.legend_elements()[0], labels=scatter.legend_elements()[1], fontsize=16)\n",
        "\n",
        "         \n",
        "#Le ponemos nombre a los ejes\n",
        "plt.xlabel(\"PC1\");\n",
        "plt.ylabel(\"PC2\");\n",
        "\n",
        "\n",
        "#Grafico las primeras dos componentes principales \n",
        "myplot(x_new[:,0:2], pca.components_, t)\n",
        "plt.xlabel(\"PC{}\".format(1))\n",
        "plt.ylabel(\"PC{}\".format(2))\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnWd55cXsPcQ"
      },
      "source": [
        "# Definimos el rango de los ejes del grafico\n",
        "plt.axis([-1, 0.25, -0.5, 1.5])\n",
        "\n",
        "# Vemos cuantos vectores son las direcciones de maxima varianza\n",
        "n = pca.components_.shape[0]\n",
        "print(n)\n",
        "print(pca.components_)\n",
        "\n",
        "# Recorremos esos vectores y los vamos dibujando en el plano\n",
        "for i in range(n):\n",
        "    plt.arrow(0, 0, pca.components_[i,0], pca.components_[i,1], color = 'g', alpha = 1)\n",
        "    # En el extremo de cada vector ponemos en nombre de la columan correspondiente (un poco dezplazados)\n",
        "    plt.text(pca.components_[i,0]*1.1 , pca.components_[i,1]*1.1, t[i], color = 'r', ha = 'center', va = 'center', fontsize=8)\n",
        "    plt.xlim(None,0.5)\n",
        "    plt.ylim(None, 0.5)\n",
        "\n",
        "# Le ponemos nombre a los ejes\n",
        "plt.xlabel(\"PC1\");\n",
        "plt.ylabel(\"PC2\");\n",
        "\n",
        "# imprimimos el grafico completo\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4bfye2XRXWk"
      },
      "source": [
        "# Clasificador bayesiano ingenuo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1Hhtw1CRY3-"
      },
      "source": [
        "gnb = GaussianNB() #instancio la clase\n",
        "modelo_gnb = gnb.fit(X_train, y_train) #entreno modelo predictivo a partir de los datos, es decir construyo en borde de decisión\n",
        "y_pred_test = modelo_gnb.predict(X_test) #clasifico según modelo. Por defecto clasifica según la clase con probablidad más alta\n",
        "\n",
        "# matriz de confusión\n",
        "conf_g = confusion_matrix(y_test,y_pred_test)\n",
        "\n",
        "# grafico matriz de confusión\n",
        "disp_g = ConfusionMatrixDisplay(confusion_matrix=conf_g, display_labels=gnb.classes_)\n",
        "disp_g.plot(values_format='d') \n",
        "\n",
        "# métricas de evaluación sobre los datos de TESTEO.\n",
        "accuracy_g = accuracy_score(y_test, y_pred_test)\n",
        "recall_g = recall_score(y_test, y_pred_test)\n",
        "precision_g = precision_score(y_test, y_pred_test)\n",
        "\n",
        "print('Métricas sobre datos de TEST')\n",
        "print('Accuracy: ', round(accuracy_g,2))\n",
        "print('Recall: ', round(recall_g,2))\n",
        "print('Precision: ', round(precision_g,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhQ4C_UGr14W"
      },
      "source": [
        "#implemento un punto de corte en 0.7\n",
        "probas = modelo_gnb.predict_proba(X_test)\n",
        "\n",
        "# por ejemplo, por defecto asumo que si termina en venta (y=1)\n",
        "y_pred_test_custom = np.ones(y_test.shape)\n",
        "\n",
        "#y si la probabilidad de y=0 es mayor a 0.7, lo clasifico como no venta (y=0)\n",
        "for i in range(probas.shape[0]):\n",
        "    if (probas[i,0]>0.2):\n",
        "        y_pred_test_custom[i]=0.\n",
        "\n",
        "# matriz de confusión\n",
        "conf_custom = confusion_matrix(y_test,y_pred_test_custom)\n",
        "\n",
        "# grafico matriz de confusión\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_custom, display_labels=gnb.classes_)\n",
        "disp.plot(values_format='d') \n",
        "\n",
        "#métricas de evaluación sobre los datos de TESTEO, punto de corte arbitrario\n",
        "accuracy_custom = accuracy_score(y_test, y_pred_test_custom)\n",
        "recall_custom = recall_score(y_test, y_pred_test_custom)\n",
        "precision_custom = precision_score(y_test, y_pred_test_custom)\n",
        "f1_custom = f1_score(y_test, y_pred_test_custom)\n",
        "clasif_report_custom = classification_report(y_test, y_pred_test_custom)\n",
        "\n",
        "print('')\n",
        "print('Métricas sobre datos nuevos de TEST, punto de corte arbitrario 0.7')\n",
        "print('Accuracy: ', round(accuracy_custom,2))\n",
        "print('Recall: ', round(recall_custom,2))\n",
        "print('Precision: ', round(precision_custom,2))\n",
        "print('F1: ', round(f1_custom,2))\n",
        "print('Classification Report:')\n",
        "print(clasif_report_custom)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVOdCprcuMxi"
      },
      "source": [
        "Clasificador Análisis Discriminante Lineal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XccSsY9NuQGB"
      },
      "source": [
        "lda = LinearDiscriminantAnalysis() #instancio la clase\n",
        "modelo_lda = lda.fit(X_train, y_train) #entreno modelo predictivo a partir de los datos, es decir construyo en borde de decisión\n",
        "y_pred_test_dl = modelo_lda.predict(X_test) #clasifico según modelo. Por defecto clasifica según la clase con probablidad más alta\n",
        "\n",
        "\n",
        "# matriz de confusión\n",
        "conf = confusion_matrix(y_test,y_pred_test_dl)\n",
        "\n",
        "# grafico matriz de confusión\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf, display_labels=lda.classes_)\n",
        "disp.plot(values_format='d') \n",
        "\n",
        "# métricas de evaluación sobre los datos de TESTEO.\n",
        "accuracy_dl = accuracy_score(y_test, y_pred_test_dl)\n",
        "recall_dl = recall_score(y_test, y_pred_test_dl)\n",
        "precision_dl = precision_score(y_test, y_pred_test_dl)\n",
        "f1_dl = f1_score(y_test, y_pred_test_dl)\n",
        "clasif_report_dl = classification_report(y_test, y_pred_test_dl)\n",
        "\n",
        "\n",
        "print('Métricas sobre datos de TEST sin punto de corte arbitrario')\n",
        "print('Accuracy: ', round(accuracy_dl,2))\n",
        "print('Recall: ', round(recall_dl,2))\n",
        "print('Precision: ', round(precision_dl,2))\n",
        "print('F1: ', round(f1_dl,2))\n",
        "print('Classification Report:')\n",
        "print(clasif_report_dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA6D3Uqz8M71"
      },
      "source": [
        "# Clasificador Regresión Logística\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QSgfgAJ3DSk"
      },
      "source": [
        "lg = LogisticRegression() #instancio la clase\n",
        "modelo_lg = lg.fit(X_train, y_train) \n",
        "# clasifico según el modelo, es decir predigo las clases, con los datos de TESTEO.\n",
        "y_pred_test = modelo_lg.predict(X_test)\n",
        "\n",
        "# matriz de confusión\n",
        "conf = confusion_matrix(y_test,y_pred_test)\n",
        "\n",
        "# grafico matriz de confusión\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf, display_labels=lg.classes_)\n",
        "disp.plot(values_format='d') \n",
        "\n",
        "# métricas de evaluación sobre los datos de TESTEO.\n",
        "accuracy = accuracy_score(y_test, y_pred_test)\n",
        "recall = recall_score(y_test, y_pred_test)\n",
        "precision = precision_score(y_test, y_pred_test)\n",
        "f1 = f1_score(y_test, y_pred_test)\n",
        "clasif_report = classification_report(y_test, y_pred_test)\n",
        "\n",
        "\n",
        "print('Métricas sobre datos de TEST sin punto de corte arbitrario')\n",
        "print('Accuracy: ', round(accuracy,2))\n",
        "print('Recall: ', round(recall,2))\n",
        "print('Precision: ', round(precision,2))\n",
        "print('F1: ', round(f1,2))\n",
        "print('Classification Report:')\n",
        "print(clasif_report)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74x4dl9CCIdB"
      },
      "source": [
        "# Coeficientes de la Regresión Logística"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyazNMOdCJj0"
      },
      "source": [
        "lg.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S77tM3UglP8P"
      },
      "source": [
        "# Evaluación en TEST por Curva ROC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZmmTw9plU8k"
      },
      "source": [
        "plot_roc_curve(modelo_lg, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VB9BhPjWmdoa"
      },
      "source": [
        "###Variando punto de corte\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4YWlrfrq1lL"
      },
      "source": [
        "\n",
        "#implemento un punto de corte en 0.7\n",
        "probas = modelo_lg.predict_proba(X_test)\n",
        "\n",
        "# por ejemplo, por defecto asumo que si termina en venta (y=1)\n",
        "y_pred_test_custom = np.ones(y_test.shape)\n",
        "\n",
        "#y si la probabilidad de y=0 es mayor a 0.7, lo clasifico como no venta (y=0)\n",
        "for i in range(probas.shape[0]):\n",
        "    if (probas[i,0]>0.2):\n",
        "        y_pred_test_custom[i]=0.\n",
        "\n",
        "# matriz de confusión\n",
        "conf_custom = confusion_matrix(y_test,y_pred_test_custom)\n",
        "\n",
        "# grafico matriz de confusión\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_custom, display_labels=lg.classes_)\n",
        "disp.plot(values_format='d') \n",
        "\n",
        "#métricas de evaluación sobre los datos de TESTEO, punto de corte arbitrario\n",
        "accuracy_custom = accuracy_score(y_test, y_pred_test_custom)\n",
        "recall_custom = recall_score(y_test, y_pred_test_custom)\n",
        "precision_custom = precision_score(y_test, y_pred_test_custom)\n",
        "f1_custom = f1_score(y_test, y_pred_test_custom)\n",
        "clasif_report_custom = classification_report(y_test, y_pred_test_custom)\n",
        "\n",
        "print('')\n",
        "print('Métricas sobre datos nuevos de TEST, punto de corte arbitrario 0.7')\n",
        "print('Accuracy: ', round(accuracy_custom,2))\n",
        "print('Recall: ', round(recall_custom,2))\n",
        "print('Precision: ', round(precision_custom,2))\n",
        "print('F1: ', round(f1_custom,2))\n",
        "print('Classification Report:')\n",
        "print(clasif_report_custom)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnaCX_cnl1z1"
      },
      "source": [
        "plot_roc_curve(modelo_lg, X_test, y_pred_test_custom)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpXOLQxfeCHR"
      },
      "source": [
        "#implemento un punto de corte en 0.7\n",
        "probas_07 = modelo_lg.predict_proba(X_test)\n",
        "\n",
        "# por ejemplo, por defecto asumo que si termina en venta (y=1)\n",
        "y_pred_test_custom_07 = np.ones(y_test.shape)\n",
        "\n",
        "#y si la probabilidad de y=0 es mayor a 0.7, lo clasifico como no venta (y=0)\n",
        "for i in range(probas.shape[0]):\n",
        "    if (probas[i,0]>0.7):\n",
        "        y_pred_test_custom_07[i]=0.\n",
        "\n",
        "# matriz de confusión\n",
        "conf_custom_07 = confusion_matrix(y_test,y_pred_test_custom_07)\n",
        "\n",
        "# grafico matriz de confusión\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_custom_07, display_labels=lg.classes_)\n",
        "disp.plot(values_format='d') \n",
        "\n",
        "#métricas de evaluación sobre los datos de TESTEO, punto de corte arbitrario\n",
        "accuracy_custom_07 = accuracy_score(y_test, y_pred_test_custom_07)\n",
        "recall_custom_07 = recall_score(y_test, y_pred_test_custom_07)\n",
        "precision_custom_07 = precision_score(y_test, y_pred_test_custom_07)\n",
        "f1_custom_07 = f1_score(y_test, y_pred_test_custom_07)\n",
        "clasif_report_custom_07 = classification_report(y_test, y_pred_test_custom_07)\n",
        "\n",
        "print('')\n",
        "print('Métricas sobre datos nuevos de TEST, punto de corte arbitrario 0.7')\n",
        "print('Accuracy: ', round(accuracy_custom_07,2))\n",
        "print('Recall: ', round(recall_custom_07,2))\n",
        "print('Precision: ', round(precision_custom_07,2))\n",
        "print('F1: ', round(f1_custom_07,2))\n",
        "print('Classification Report:')\n",
        "print(clasif_report_custom_07)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVJkWly5mNOw"
      },
      "source": [
        "plot_roc_curve(modelo_lg, X_test, y_pred_test_custom_07)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXVhWdG4efS9"
      },
      "source": [
        "# Clasificador Regresión Logística sin usar train/test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo-wlt4BJKpC"
      },
      "source": [
        "lg_base = LogisticRegression() #instancio la clase\n",
        "modelo_lg_base =lg_base.fit(X, y) \n",
        "# clasifico según el modelo, es decir predigo las clases, con los datos de TESTEO.\n",
        "y_pred_test_base = modelo_lg_base.predict(X)\n",
        "\n",
        "# matriz de confusión\n",
        "conf_base = confusion_matrix(y,y_pred_test_base)\n",
        "\n",
        "# grafico matriz de confusión\n",
        "disp_base = ConfusionMatrixDisplay(confusion_matrix=conf_base, display_labels=lg_base.classes_)\n",
        "disp_base.plot(values_format='d') \n",
        "\n",
        "# métricas de evaluación sobre los datos de TESTEO.\n",
        "accuracy = accuracy_score(y, y_pred_test_base)\n",
        "recall = recall_score(y, y_pred_test_base)\n",
        "precision = precision_score(y, y_pred_test_base)\n",
        "\n",
        "print('Métricas sobre datos sin TEST')\n",
        "print('Accuracy: ', round(accuracy,2))\n",
        "print('Recall: ', round(recall,2))\n",
        "print('Precision: ', round(precision,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUC2bEMegP6c"
      },
      "source": [
        "# Coeficientes de la Regresión Logística sin usar train/test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwZf_JRmgWye"
      },
      "source": [
        "lg_base.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj4nLufzBvYz"
      },
      "source": [
        "Aplico componentes principales al modelo de regrecion logistica elegido como mejor 20% de datos para test y punto de corte 0.8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScIItGf2CFqm"
      },
      "source": [
        "pca_reglog = PCA()\n",
        "pca_reglog.fit(X,y_pred_test_custom)\n",
        "x_new_reglog = pca_reglog.transform(X)\n",
        "pca_reglog.components_[:,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pVdvXPcDGlQ"
      },
      "source": [
        "print([round(x,3) for x in pca_reglog.components_[:,0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1Le2KSdC1n_"
      },
      "source": [
        "pca_reglog.components_[:,1] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNf06RuLDdKu"
      },
      "source": [
        "print([round(x,3) for x in pca_reglog.components_[:,1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOlqlPpQDq34"
      },
      "source": [
        "#Varianza explicada por cada componente\n",
        "print(pca_reglog.explained_variance_ratio_)\n",
        "print([round(x,3) for x in pca_reglog.explained_variance_ratio_])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xKTg1HDD8in"
      },
      "source": [
        "# Grafico las primeras dos componentes principales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISRdCvT8EmnR"
      },
      "source": [
        "def myplot(score,coeff,labels=None,target_names=None,titulo1='Vista PCA',titulo2='Vista proyeccion var originales'):\n",
        "     x1 = score[:,0]\n",
        "     x2 = score[:,1]\n",
        "     n = coeff.shape[0]\n",
        "\n",
        "     clases = target_names\n",
        "     scatter = plt.scatter(x1, x2, c=y, alpha=1) #, cmap=colours)\n",
        "     plt.legend(handles=scatter.legend_elements()[0], labels=clases, fontsize=19)\n",
        "     print(scatter.legend_elements())\n",
        "     plt.legend(handles=scatter.legend_elements()[0], labels=scatter.legend_elements()[1], fontsize=16)\n",
        "\n",
        "         \n",
        "#Le ponemos nombre a los ejes\n",
        "plt.xlabel(\"PC1\");\n",
        "plt.ylabel(\"PC2\");\n",
        "\n",
        "\n",
        "#Grafico las primeras dos componentes principales \n",
        "myplot(x_new_reglog[:,0:2], pca_reglog.components_, t)\n",
        "plt.xlabel(\"PC{}\".format(1))\n",
        "plt.ylabel(\"PC{}\".format(2))\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuLO-iDfFfKy"
      },
      "source": [
        "# Definimos el rango de los ejes del grafico\n",
        "plt.axis([-1,0.25,-0.5,1])\n",
        "\n",
        "# Vemos cuantos vectores son las direcciones de maxima varianza\n",
        "n_reglog = pca_reglog.components_.shape[0]\n",
        "print(n_reglog)\n",
        "print(pca_reglog.components_)\n",
        "\n",
        "# Recorremos esos vectores y los vamos dibujando en el plano\n",
        "for i in range(n):\n",
        "    plt.arrow(0, 0, pca_reglog.components_[i,0], pca_reglog.components_[i,1], color = 'g', alpha = 1)\n",
        "    # En el extremo de cada vector ponemos en nombre de la columan correspondiente (un poco dezplazados)\n",
        "    plt.text(pca_reglog.components_[i,0]*1.1 , pca_reglog.components_[i,1]*1.1, t[i], color = 'r', ha = 'center', va = 'center', fontsize=8)\n",
        "    plt.xlim(None,0.5)\n",
        "    plt.ylim(None, 0.5)\n",
        "\n",
        "# Le ponemos nombre a los ejes\n",
        "plt.xlabel(\"PC1\");\n",
        "plt.ylabel(\"PC2\");\n",
        "\n",
        "# imprimimos el grafico completo\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}